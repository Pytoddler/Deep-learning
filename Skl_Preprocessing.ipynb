{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarize: 給定界定數字，>就是1，<就是0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before transform: [[1, 2, 3, 4, 5], [5, 4, 3, 2, 1], [3, 3, 3, 3, 3], [1, 1, 1, 1, 1]]\n",
      "after transform: [[0 0 1 1 1]\n",
      " [1 1 1 0 0]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "def test_Binarizer():\n",
    "    \n",
    "    '''\n",
    "    测试 Binarizer 的用法\n",
    "    :return: None\n",
    "    '''\n",
    "    \n",
    "    X=[   [1,2,3,4,5],\n",
    "          [5,4,3,2,1],\n",
    "          [3,3,3,3,3,],\n",
    "          [1,1,1,1,1] ]\n",
    "    print(\"before transform:\",X)\n",
    "    \n",
    "    binarizer = Binarizer(threshold=2.5)\n",
    "    print(\"after transform:\",binarizer.transform(X))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    test_Binarizer() # 调用 test_Binarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onehot-encoding: 2D原理比較不懂..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before transform: [[1, 2, 3, 4, 5], [5, 4, 3, 2, 1], [3, 3, 3, 3, 3], [1, 1, 1, 1, 1]]\n",
      "active_features_: [ 1  3  5  7  8  9 10 12 14 16 17 18 19 21 23 25]\n",
      "feature_indices_: [ 0  6 11 15 20 26]\n",
      "n_values_: [6 5 4 5 6]\n",
      "after transform: [[ 1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def test_OneHotEncoder():\n",
    "    \n",
    "    '''\n",
    "    测试 OneHotEncoder 的用法\n",
    "    :return: None\n",
    "    '''\n",
    "    \n",
    "    X=[   [1,2,3,4,5],\n",
    "          [5,4,3,2,1],\n",
    "          [3,3,3,3,3,],\n",
    "          [1,1,1,1,1] ]\n",
    "    print(\"before transform:\",X)\n",
    "    \n",
    "    encoder=OneHotEncoder(sparse=False)\n",
    "    encoder.fit(X)\n",
    "    \n",
    "    print(\"active_features_:\",encoder.active_features_)\n",
    "    print(\"feature_indices_:\",encoder.feature_indices_)\n",
    "    print(\"n_values_:\",encoder.n_values_)\n",
    "    print(\"after transform:\",encoder.transform( [[1,2,3,4,5]]))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    test_OneHotEncoder() # 调用 test_OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D categorical variable常用在label輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before transform:\n",
      " [[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n",
      "active_features_: [0 1 2 3 4 5 6 7 8 9]\n",
      "feature_indices_: [ 0 10]\n",
      "n_values_: [10]\n",
      "after transform:\n",
      " [[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def test_OneHotEncoder():\n",
    "    \n",
    "    '''\n",
    "    测试 OneHotEncoder 的用法\n",
    "    :return: None\n",
    "    '''\n",
    "    \n",
    "    X= np.arange(10).reshape(-1,1) #MNIST 0~9數字辨識答案\n",
    "    print(\"before transform:\\n\",X)\n",
    "    \n",
    "    encoder=OneHotEncoder(sparse=False)\n",
    "    encoder.fit(X)\n",
    "    \n",
    "    print(\"active_features_:\",encoder.active_features_)\n",
    "    print(\"feature_indices_:\",encoder.feature_indices_)\n",
    "    print(\"n_values_:\",encoder.n_values_)\n",
    "    print(\"after transform:\\n\",encoder.transform( X ))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    test_OneHotEncoder() # 调用 test_OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize: 都是根據column value做轉換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMaxScaler: column value中 x-min/(max-min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before transform: [[1, 5, 1, 2, 10], [2, 6, 3, 2, 7], [3, 7, 5, 6, 4], [4, 8, 7, 8, 1], [5, 9, 2, 5, 2]]\n",
      "min_ is : [-0.25       -1.25       -0.16666667 -0.33333333 -0.11111111]\n",
      "scale_ is : [ 0.25        0.25        0.16666667  0.16666667  0.11111111]\n",
      "data_max_ is : [  5.   9.   7.   8.  10.]\n",
      "data_min_ is : [ 1.  5.  1.  2.  1.]\n",
      "data_range_ is : [ 4.  4.  6.  6.  9.]\n",
      "after transform: [[ 0.          0.          0.          0.          1.        ]\n",
      " [ 0.25        0.25        0.33333333  0.          0.66666667]\n",
      " [ 0.5         0.5         0.66666667  0.66666667  0.33333333]\n",
      " [ 0.75        0.75        1.          1.          0.        ]\n",
      " [ 1.          1.          0.16666667  0.5         0.11111111]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,MaxAbsScaler,StandardScaler\n",
    "\n",
    "def test_MinMaxScaler():\n",
    "    \n",
    "    '''\n",
    "    测试 MinMaxScaler 的用法\n",
    "    :return: None\n",
    "    '''\n",
    "    \n",
    "    X=[   [1,5,1,2,10],\n",
    "      [2,6,3,2,7],\n",
    "      [3,7,5,6,4],\n",
    "      [4,8,7,8,1],\n",
    "      [5,9,2,5,2]]\n",
    "    print(\"before transform:\",X)\n",
    "    \n",
    "    scaler=MinMaxScaler(feature_range=(0,1))\n",
    "    scaler.fit(X)\n",
    "    \n",
    "    print(\"min_ is :\",scaler.min_)\n",
    "    print(\"scale_ is :\",scaler.scale_)\n",
    "    print(\"data_max_ is :\",scaler.data_max_)\n",
    "    print(\"data_min_ is :\",scaler.data_min_)\n",
    "    print(\"data_range_ is :\",scaler.data_range_)\n",
    "    print(\"after transform:\",scaler.transform(X))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    test_MinMaxScaler()  # 调用 test_MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxAbsScaler: column value中 x/max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before transform: [[1, 5, 1, 2, 10], [2, 6, 3, 2, 7], [3, 7, 5, 6, 4], [4, 8, 7, 8, 1]]\n",
      "scale_ is : [  4.   8.   7.   8.  10.]\n",
      "max_abs_ is : [  4.   8.   7.   8.  10.]\n",
      "after transform: [[ 0.25        0.625       0.14285714  0.25        1.        ]\n",
      " [ 0.5         0.75        0.42857143  0.25        0.7       ]\n",
      " [ 0.75        0.875       0.71428571  0.75        0.4       ]\n",
      " [ 1.          1.          1.          1.          0.1       ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,MaxAbsScaler,StandardScaler\n",
    "\n",
    "def test_MaxAbsScaler():\n",
    "    '''\n",
    "    测试 MaxAbsScaler 的用法\n",
    "    :return: None\n",
    "    '''\n",
    "    X=[   [1,5,1,2,10],\n",
    "      [2,6,3,2,7],\n",
    "      [3,7,5,6,4,],\n",
    "      [4,8,7,8,1] ]\n",
    "    print(\"before transform:\",X)\n",
    "    \n",
    "    scaler=MaxAbsScaler()\n",
    "    scaler.fit(X)\n",
    "    \n",
    "    print(\"scale_ is :\",scaler.scale_)\n",
    "    print(\"max_abs_ is :\",scaler.max_abs_)\n",
    "    print(\"after transform:\",scaler.transform(X))\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    test_MaxAbsScaler()  # 调用 test_MaxAbsScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StandardScaler: column value中 x-mean()/std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before transform: [[1, 5, 1, 2, 10], [2, 6, 3, 2, 7], [3, 7, 5, 6, 4], [4, 8, 7, 8, 1]]\n",
      "scale_ is : [ 1.11803399  1.11803399  2.23606798  2.59807621  3.35410197]\n",
      "mean_ is : [ 2.5  6.5  4.   4.5  5.5]\n",
      "var_ is : [  1.25   1.25   5.     6.75  11.25]\n",
      "after transform: [[-1.34164079 -1.34164079 -1.34164079 -0.96225045  1.34164079]\n",
      " [-0.4472136  -0.4472136  -0.4472136  -0.96225045  0.4472136 ]\n",
      " [ 0.4472136   0.4472136   0.4472136   0.57735027 -0.4472136 ]\n",
      " [ 1.34164079  1.34164079  1.34164079  1.34715063 -1.34164079]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,MaxAbsScaler,StandardScaler\n",
    "\n",
    "def test_StandardScaler():\n",
    "    '''\n",
    "    测试 StandardScaler 的用法\n",
    "    :return: None\n",
    "    '''\n",
    "    X=[   [1,5,1,2,10],\n",
    "      [2,6,3,2,7],\n",
    "      [3,7,5,6,4,],\n",
    "      [4,8,7,8,1] ]\n",
    "    print(\"before transform:\",X)\n",
    "    \n",
    "    scaler=StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    \n",
    "    print(\"scale_ is :\",scaler.scale_)\n",
    "    print(\"mean_ is :\",scaler.mean_)\n",
    "    print(\"var_ is :\",scaler.var_)\n",
    "    print(\"after transform:\",scaler.transform(X))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    test_StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize 正則化（regularize?）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before transform: [[1, 2, 3, 4, 5], [5, 4, 3, 2, 1], [1, 3, 5, 2, 4], [2, 4, 1, 3, 5]]\n",
      "after transform: [[ 0.13483997  0.26967994  0.40451992  0.53935989  0.67419986]\n",
      " [ 0.67419986  0.53935989  0.40451992  0.26967994  0.13483997]\n",
      " [ 0.13483997  0.40451992  0.67419986  0.26967994  0.53935989]\n",
      " [ 0.26967994  0.53935989  0.13483997  0.40451992  0.67419986]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "def test_Normalizer():\n",
    "    '''\n",
    "    测试 Normalizer 的用法\n",
    "    :return: None\n",
    "    '''\n",
    "    X=[   [1,2,3,4,5],\n",
    "          [5,4,3,2,1],\n",
    "          [1,3,5,2,4,],\n",
    "          [2,4,1,3,5] ]\n",
    "    print(\"before transform:\",X)\n",
    "    \n",
    "    normalizer=Normalizer(norm='l2')\n",
    "    \n",
    "    print(\"after transform:\",normalizer.transform(X))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    test_Normalizer() # 调用 test_Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature_selection_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VarianceThreshold: column value中variance小於某個數字，代表越重要，給0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variances is [  0.1875  13.6875  13.6875  13.6875]\n",
      "After transform is [[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [11 12 13]]\n",
      "The surport is [1 2 3]\n",
      "After reverse transform is [[ 0  1  2  3]\n",
      " [ 0  4  5  6]\n",
      " [ 0  7  8  9]\n",
      " [ 0 11 12 13]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import  VarianceThreshold,SelectKBest,f_classif\n",
    "\n",
    "def test_VarianceThreshold():\n",
    "    '''\n",
    "    测试 VarianceThreshold  的用法\n",
    "    :return:  None\n",
    "    '''\n",
    "    X=[[100,1,2,3],\n",
    "       [100,4,5,6],\n",
    "       [100,7,8,9],\n",
    "       [101,11,12,13]]\n",
    "    \n",
    "    selector=VarianceThreshold(threshold=1) #覆蓋掉variance的閾值\n",
    "    selector.fit(X)\n",
    "    \n",
    "    print(\"Variances is %s\"%selector.variances_)\n",
    "    print(\"After transform is %s\"%selector.transform(X))\n",
    "    print(\"The surport is %s\"%selector.get_support(True))\n",
    "    print(\"After reverse transform is %s\"%\n",
    "            selector.inverse_transform(selector.transform(X)))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    test_VarianceThreshold() # 调用 test_VarianceThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SelectKBest: 保留統計指標上得分最高的k個項目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before transform: [[1, 2, 3, 4, 5], [5, 4, 3, 2, 1], [3, 3, 3, 3, 3], [1, 1, 1, 1, 1]]\n",
      "scores_: [ 0.2  0.   1.   8.   9. ]\n",
      "pvalues_: [ 0.69848866  1.          0.42264973  0.10557281  0.09546597]\n",
      "selected index: [2 3 4]\n",
      "after transform: [[3 4 5]\n",
      " [3 2 1]\n",
      " [3 3 3]\n",
      " [1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import  VarianceThreshold,SelectKBest,f_classif\n",
    "\n",
    "def test_SelectKBest():\n",
    "    '''\n",
    "    测试 SelectKBest  的用法，其中考察的特征指标是 f_classif\n",
    "    :return:  None\n",
    "    '''\n",
    "    X=[   [1,2,3,4,5],\n",
    "          [5,4,3,2,1],\n",
    "          [3,3,3,3,3,],\n",
    "          [1,1,1,1,1] ]\n",
    "    y=[0,1,0,1]\n",
    "    print(\"before transform:\",X)\n",
    "    \n",
    "    selector=SelectKBest(score_func=f_classif,k=3) #保留統計指標上得分最高的k個項目\n",
    "    selector.fit(X,y)\n",
    "    \n",
    "    print(\"scores_:\",selector.scores_)\n",
    "    print(\"pvalues_:\",selector.pvalues_)\n",
    "    print(\"selected index:\",selector.get_support(True))\n",
    "    print(\"after transform:\",selector.transform(X))\n",
    "\n",
    "    if __name__=='__main__':\n",
    "    test_SelectKBest() # 调用 test_SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature_selection_bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE: 由外部選擇器選擇n個特徵（由於會踢除訊息，訓練效果可能不會更好）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_features 2\n",
      "Support is [False  True False  True]\n",
      "Ranking [3 1 2 1]\n",
      "Original DataSet: test score=0.973684210526\n",
      "Selected DataSet: test score=0.947368421053\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import  RFE,RFECV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import  load_iris\n",
    "from  sklearn import  cross_validation\n",
    "\n",
    "def test_RFE():\n",
    "    '''\n",
    "    测试 RFE 的用法，其中目标特征数量为 2\n",
    "    :return: None\n",
    "    '''\n",
    "    iris=load_iris()\n",
    "    X=iris.data\n",
    "    y=iris.target\n",
    "    estimator=LinearSVC()\n",
    "    selector=RFE(estimator=estimator,n_features_to_select=2) #決定最後只選擇2個特徵\n",
    "    selector.fit(X,y)\n",
    "    print(\"N_features %s\"%selector.n_features_)\n",
    "    print(\"Support is %s\"%selector.support_)\n",
    "    print(\"Ranking %s\"%selector.ranking_)\n",
    "\n",
    "def test_compare_with_no_feature_selection():\n",
    "    '''\n",
    "    比较经过特征选择和未经特征选择的数据集，对 LinearSVC 的预测性能的区别\n",
    "    :return: None\n",
    "    '''\n",
    "    ### 加载数据\n",
    "    iris=load_iris()\n",
    "    X,y=iris.data,iris.target\n",
    "    ### 特征提取\n",
    "    estimator=LinearSVC()\n",
    "    selector=RFE(estimator=estimator,n_features_to_select=2)\n",
    "    X_t=selector.fit_transform(X,y)\n",
    "    #### 切分测试集与验证集\n",
    "    X_train,X_test,y_train,y_test=cross_validation.train_test_split(X, y,\n",
    "                test_size=0.25,random_state=0,stratify=y)\n",
    "    X_train_t,X_test_t,y_train_t,y_test_t=cross_validation.train_test_split(X_t, y,\n",
    "                test_size=0.25,random_state=0,stratify=y)\n",
    "    ### 测试与验证\n",
    "    clf=LinearSVC()\n",
    "    clf_t=LinearSVC()\n",
    "    clf.fit(X_train,y_train)\n",
    "    clf_t.fit(X_train_t,y_train_t)\n",
    "    print(\"Original DataSet: test score=%s\"%(clf.score(X_test,y_test)))\n",
    "    print(\"Selected DataSet: test score=%s\"%(clf_t.score(X_test_t,y_test_t)))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    test_RFE() # 调用 test_RFE\n",
    "    test_compare_with_no_feature_selection() # 调用 test_compare_with_no_feature_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFE引入cross validation，不用給定選取n個特徵，他會自己判斷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_features 4\n",
      "Support is [ True  True  True  True]\n",
      "Ranking [1 1 1 1]\n",
      "Grid Scores [ 0.91421569  0.94689542  0.95383987  0.96691176]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import  RFE,RFECV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import  load_iris\n",
    "from  sklearn import  cross_validation\n",
    "\n",
    "def test_RFECV():\n",
    "    '''\n",
    "    测试 RFECV 的用法\n",
    "    :return:  None\n",
    "    '''\n",
    "    iris=load_iris()\n",
    "    X=iris.data\n",
    "    y=iris.target\n",
    "    estimator=LinearSVC()\n",
    "    selector=RFECV(estimator=estimator,cv=3) #預設最少3次\n",
    "    selector.fit(X,y)\n",
    "    print(\"N_features %s\"%selector.n_features_)\n",
    "    print(\"Support is %s\"%selector.support_)\n",
    "    print(\"Ranking %s\"%selector.ranking_)\n",
    "    print(\"Grid Scores %s\"%selector.grid_scores_)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    test_RFECV() # 调用 test_RFECV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature_selection_embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.682159260091\n",
      "Support is [ 2  3  4  5  6  9 12 13 14 16 18 19 20 21 22 24 26 27 30 33 36 38 41 42 43\n",
      " 44 45 51 53 54 55 61]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import  load_digits,load_diabetes\n",
    "import numpy as np\n",
    "import  matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def test_SelectFromModel():\n",
    "    '''\n",
    "    测试 SelectFromModel 的用法。\n",
    "    :return: None\n",
    "    '''\n",
    "    digits=load_digits()\n",
    "    X=digits.data\n",
    "    y=digits.target\n",
    "    estimator=LinearSVC(penalty='l1',dual=False)\n",
    "    selector=SelectFromModel(estimator=estimator,threshold='mean')\n",
    "    selector.fit(X,y)\n",
    "    selector.transform(X)\n",
    "    print(\"Threshold %s\"%selector.threshold_)\n",
    "    print(\"Support is %s\"%selector.get_support(indices=True))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    test_SelectFromModel() # 调用 test_SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso: alpha越大，稀疏性越大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEaCAYAAAAcz1CnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10aec8710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import  load_digits,load_diabetes\n",
    "import numpy as np\n",
    "import  matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso\n",
    "    \n",
    "def test_Lasso(*data):\n",
    "    '''\n",
    "    测试 alpha 与稀疏性的关系\n",
    "    :param data: 可变参数。它是一个元组，这里要求其元素依次为：训练样本集、测试样本集、训练样本的值、测试样本的值\n",
    "    :return: None\n",
    "    '''\n",
    "    X,y=data\n",
    "    alphas=np.logspace(-2,2)\n",
    "    zeros=[]\n",
    "    for alpha in alphas:\n",
    "        regr=Lasso(alpha=alpha)\n",
    "        regr.fit(X,y)\n",
    "        ### 计算零的个数 ###\n",
    "        num=0\n",
    "        for ele in regr.coef_:\n",
    "            if abs(ele) < 1e-5:num+=1\n",
    "        zeros.append(num)\n",
    "    ##### 绘图\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "    ax.plot(alphas,zeros)\n",
    "    ax.set_xlabel(r\"$\\alpha$\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_ylim(0,X.shape[1]+1)\n",
    "    ax.set_ylabel(\"zeros in coef\")\n",
    "    ax.set_title(\"Sparsity In Lasso\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__=='__main__':\n",
    "    data=load_diabetes() # 生成用于回归问题的数据集\n",
    "    test_Lasso(data.data,data.target) # 调用 test_Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearSVC: C越大，稀疏性大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEaCAYAAAAL7cBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e06ae48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import  load_digits,load_diabetes\n",
    "import numpy as np\n",
    "import  matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def test_LinearSVC(*data):\n",
    "    '''\n",
    "    测试 C  与 稀疏性的关系\n",
    "    :param data: 可变参数。它是一个元组，这里要求其元素依次为：训练样本集、测试样本集、训练样本的标记、测试样本的标记\n",
    "    :return: None\n",
    "    '''\n",
    "    X,y=data\n",
    "    Cs=np.logspace(-2,2)\n",
    "    zeros=[]\n",
    "    for C in Cs:\n",
    "        clf=LinearSVC(C=C,penalty='l1',dual=False)\n",
    "        clf.fit(X,y)\n",
    "         ### 计算零的个数 ###\n",
    "        num=0\n",
    "        for row in clf.coef_:\n",
    "            for ele in row:\n",
    "                if abs(ele) < 1e-5:num+=1\n",
    "        zeros.append(num)\n",
    "    ##### 绘图\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "    ax.plot(Cs,zeros)\n",
    "    ax.set_xlabel(\"C\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_ylabel(\"zeros in coef\")\n",
    "    ax.set_title(\"Sparsity In SVM\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__=='__main__':\n",
    "    data=load_digits() # 生成用于分类问题的数据集\n",
    "    test_LinearSVC(data.data,data.target) # 调用 test_LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before transform: [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [10, 9, 8, 7, 6], [5, 4, 3, 2, 1]]\n",
      "components is : [[-0.33429924 -0.38756184 -0.44082444 -0.49408705 -0.54734965]\n",
      " [ 0.13483997  0.26967994  0.40451992  0.53935989  0.67419986]\n",
      " [ 0.64742841  0.53185102  0.41627363  0.30069623  0.18511884]]\n",
      "after transform: [[  0.           7.41619849   0.        ]\n",
      " [-18.16560378   0.           0.        ]\n",
      " [  0.           0.          17.806719  ]\n",
      " [  0.           0.           7.39987833]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import DictionaryLearning\n",
    "\n",
    "def test_DictionaryLearning():\n",
    "    '''\n",
    "    测试 DictionaryLearning 的用法\n",
    "    :return: None\n",
    "    '''\n",
    "    X=[[1,2,3,4,5],\n",
    "       [6,7,8,9,10],\n",
    "       [10,9,8,7,6,],\n",
    "       [5,4,3,2,1] ]\n",
    "    print(\"before transform:\",X)\n",
    "    \n",
    "    dct=DictionaryLearning(n_components=3) #把5個feature轉換成3個feature\n",
    "    dct.fit(X)\n",
    "    \n",
    "    print(\"components is :\",dct.components_)\n",
    "    print(\"after transform:\",dct.transform(X))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    test_DictionaryLearning() # 调用 test_DictionaryLearning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline: 把所有的feature transformation過程用pipeline串接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named steps: {'LogisticRegression': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), 'MinMaxScaler': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
      "Pipeline Score: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import  cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def test_Pipeline(data):\n",
    "    '''\n",
    "    测试 Pipeline 的用法\n",
    "    :param data:  一个元组，这里要求其元素依次为：训练样本集、测试样本集、训练样本的标记、测试样本的标记\n",
    "    :return: None\n",
    "    '''\n",
    "    \n",
    "    X_train,X_test,y_train,y_test=data\n",
    "    \n",
    "    #最重要的steps: 由tuple構成，(自己定義的名稱,model)\n",
    "    steps=[('MinMaxScaler',MinMaxScaler(feature_range=(0,1))),\n",
    "           (\"LogisticRegression\",LogisticRegression(C=1))]\n",
    "    \n",
    "    pipeline=Pipeline(steps)\n",
    "    pipeline.fit(X_train,y_train)\n",
    "    \n",
    "    print(\"Named steps:\",pipeline.named_steps)\n",
    "    print(\"Pipeline Score:\",pipeline.score(X_test,y_test))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    data=load_digits() # 生成用于分类问题的数据集\n",
    "    test_Pipeline(cross_validation.train_test_split(data.data, data.target,test_size=0.25\n",
    "                                                     ,random_state=0,stratify=data.target)) # 调用 test_Pipeline"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
