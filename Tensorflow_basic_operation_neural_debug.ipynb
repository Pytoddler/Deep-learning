{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本語法：基本上全部都是向量和矩陣（張量）的預算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run Session一定要記得init變量們！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_c= 2\n",
      "ts_x= 7\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "ts_c = tf.constant(2,name='ts_c')\n",
    "ts_x = tf.Variable(ts_c+5,name='ts_x')\n",
    "\n",
    "#開啟Session，init變量\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print('ts_c=',sess.run(ts_c))\n",
    "print('ts_x=',sess.run(ts_x))\n",
    "\n",
    "sess.close() #記得關掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_c= 2\n",
      "ts_x= 7\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "ts_c = tf.constant(2,name='ts_c')\n",
    "ts_x = tf.Variable(ts_c+5,name='ts_x')\n",
    "\n",
    "#使用with就不用關掉了\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    print('ts_c=',sess.run(ts_c))\n",
    "    print('ts_x=',sess.run(ts_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## placeholoder 先做出模型，再讓張量流過去(tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用feed_dict的格式填入變數的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area= 48\n"
     ]
    }
   ],
   "source": [
    "width = tf.placeholder(\"int32\")\n",
    "height = tf.placeholder(\"int32\")\n",
    "area = tf.multiply(width,height)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    print('area=',sess.run(area,feed_dict={width: 6, height: 8}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor 1 dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.40000001  0.2         0.40000001]\n"
     ]
    }
   ],
   "source": [
    "ts_X = tf.Variable([0.4,0.2,0.4]) #一層中括號代表一維！！\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    X=sess.run(ts_X)\n",
    "    print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor 2 dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.40000001  0.2         0.40000001]]\n"
     ]
    }
   ],
   "source": [
    "ts_X = tf.Variable([[0.4,0.2,0.4]]) #兩層中括號就代表是二維！！\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    X=sess.run(ts_X)\n",
    "    print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.40000001  0.2         0.40000001]\n",
      " [ 0.5         0.69999999  0.2       ]]\n"
     ]
    }
   ],
   "source": [
    "ts_X = tf.Variable([[0.4,0.2,0.4],\n",
    "                    [0.5,0.7,0.2]]) #兩層中括號就代表是二維！！\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    X=sess.run(ts_X)\n",
    "    print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矩陣相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.29999995  0.40000001]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.Variable([[1.,1.,1.]]) #1x3\n",
    "\n",
    "W = tf.Variable([[-0.5,-0.2 ], #3x2\n",
    "                 [-0.3, 0.4 ],\n",
    "                 [-0.5, 0.2 ]])\n",
    "                        \n",
    "XW =tf.matmul(X,W) #結果應該為1x2\n",
    "                       \n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    print(sess.run(XW)) #果然是1x2矩陣"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矩陣相加 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum:\n",
      "[[-1.19999993  0.60000002]]\n"
     ]
    }
   ],
   "source": [
    "b = tf.Variable([[ 0.1,0.2]])\n",
    "XW =tf.Variable([[-1.3,0.4]])\n",
    "\n",
    "Sum =XW+b\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    print('Sum:')    \n",
    "    print(sess.run(Sum ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 單一無激活神經元層運作: y= (W,X) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XWb:\n",
      "[[-1.19999993  0.60000002]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "X = tf.Variable([[1.,1.,1.]])\n",
    "\n",
    "W = tf.Variable([[-0.5,-0.2 ],\n",
    "                 [-0.3, 0.4 ],\n",
    "                 [-0.5, 0.2 ]])\n",
    "                         \n",
    "\n",
    "b = tf.Variable([[0.1,0.2]])\n",
    "    \n",
    "XWb =tf.matmul(X,W)+b\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    print('XWb:')    \n",
    "    print(sess.run(XWb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# y = relu( (W,X) + b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XWb:\n",
      "[[-0.35999998  0.28      ]]\n",
      "y:\n",
      "[[ 0.    0.28]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "X = tf.Variable([[0.4,0.2,0.4]])\n",
    "\n",
    "W = tf.Variable([[-0.5,-0.2 ],\n",
    "                 [-0.3, 0.4 ],\n",
    "                 [-0.5, 0.2 ]])\n",
    "                         \n",
    "b = tf.Variable([[0.1,0.2]])\n",
    "    \n",
    "XWb =tf.matmul(X,W)+b\n",
    "\n",
    "y=tf.nn.relu(tf.matmul(X,W)+b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    print('XWb:')    \n",
    "    print(sess.run(XWb ))    \n",
    "    print('y:')    \n",
    "    print(sess.run(y ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# y = sigmoid( (W,X) + b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XWb:\n",
      "[[-0.35999998  0.28      ]]\n",
      "y:\n",
      "[[ 0.41095957  0.56954622]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "X = tf.Variable([[0.4,0.2,0.4]])\n",
    "\n",
    "W = tf.Variable([[-0.5,-0.2 ],\n",
    "                 [-0.3, 0.4 ],\n",
    "                 [-0.5, 0.2 ]])\n",
    "                         \n",
    "b = tf.Variable([[0.1,0.2]])\n",
    "    \n",
    "XWb =tf.matmul(X,W)+b\n",
    "\n",
    "y=tf.nn.sigmoid(tf.matmul(X,W)+b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    print('XWb:')    \n",
    "    print(sess.run(XWb ))    \n",
    "    print('y:')    \n",
    "    print(sess.run(y ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以亂數產生Weight(W)與bais(b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XWb:\n",
      "[[-0.94103545 -0.19624197 -1.43050456  0.02350724]]\n",
      "y:\n",
      "[[ 0.28069124  0.45109639  0.19302008  0.50587654]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "X = tf.Variable([[0.4,0.2,0.4]]) #1x3\n",
    "W = tf.Variable(tf.random_normal([3, 4])) #3x4\n",
    "b = tf.Variable(tf.random_normal([1, 4])) #1x4\n",
    "    \n",
    "XWb =tf.matmul(X,W)+b\n",
    "\n",
    "y=tf.nn.sigmoid(tf.matmul(X,W)+b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    print('XWb:')    \n",
    "    print(sess.run(XWb ))    \n",
    "    print('y:')    \n",
    "    print(sess.run(y ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholder 加上 亂數W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:\n",
      "[[ 0.52626228 -0.12628986  0.86360776  0.34761906]]\n",
      "W:\n",
      "[[-0.30435893 -0.52809989 -0.97243261 -2.41669965]\n",
      " [-0.37699962  0.71462435  1.69191372  0.57962149]\n",
      " [ 0.75271809  1.11475492 -0.59023786 -1.30476356]]\n",
      "X:\n",
      "[[ 0.40000001  0.2         0.40000001]]\n",
      "y:\n",
      "[[ 0.63020599  0.251297    0.5769223   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# X維度是1x3\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 4]))\n",
    "b = tf.Variable(tf.random_normal([1, 4]))\n",
    "\n",
    "X = tf.placeholder(\"float\", [None,3]) #nx3\n",
    "\n",
    "y=tf.nn.relu(tf.matmul(X,W)+b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    X_array = np.array([[0.4,0.2,0.4]])\n",
    "    (_b,_W,_X,_y)=sess.run((b,W,X,y),feed_dict={X:X_array}) #只需要feed X，其他都包裝好了\n",
    "    \n",
    "    print('b:')\n",
    "    print(_b)    \n",
    "    print('W:')\n",
    "    print(_W)\n",
    "    print('X:')\n",
    "    print(_X)\n",
    "    print('y:')\n",
    "    print(_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "[-0.27391231  0.89868158 -0.34509102 -2.44910693  0.46767321  0.23288742\n",
      "  0.16783336 -0.31754726 -0.5609262  -0.14726901  0.69067568 -0.53074038\n",
      "  0.4618527   1.26630211 -0.26246893 -0.7228418   0.42280659  0.06118865\n",
      "  0.40003428  1.62991965 -1.1498239  -0.51341015 -0.10593808 -0.2603403\n",
      " -1.69936824 -0.2910226  -1.18126643  0.16013452 -1.13885581 -1.21241951]\n"
     ]
    }
   ],
   "source": [
    "ts_norm = tf.random_normal([1000])\n",
    "with tf.Session() as session:\n",
    "    norm_data=ts_norm.eval()\n",
    "print(len(norm_data))\n",
    "print(norm_data[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADhxJREFUeJzt3X+oX/V9x/Hnq+rcUMcU70Iaw66FbCyOLcIlDFqGw626\nOhb9YxIZxTFZWrCtQscWLcxuI2DZajfGLEtRmoLTBVQUdGvVCc4//HEVpybRNdRIEqK5rSsqA0fi\ne3/cY/3OJfl+7/dHvvd+8nzA5XvO53zO9/M+JHndT8453/NNVSFJatfHpl2AJGmyDHpJapxBL0mN\nM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS406fdgEA559/fs3Ozk67DElaUZ577rkfVtVMv359\ngz7JWuA7wCqggO1V9XdJvgr8MbDQdb25qh7u9rkJuA44Cnypqr57ojFmZ2eZn5/vV4okqUeS1wfp\nN8iM/gjw5ap6Psk5wHNJHum2faOq/uYjA68HNgMXAR8HHk3yi1V1dPDyJUnj0vccfVUdqqrnu+V3\ngD3AmhPssgm4p6req6rXgL3AxnEUK0lauiVdjE0yC1wMPN01fTHJi0nuTHJu17YG2N+z2wFO/ItB\nkjRBAwd9krOBe4Ebq+pt4JvAJ4ANwCHg60sZOMmWJPNJ5hcWFvrvIEkaykBBn+QMFkP+rqq6D6Cq\n3qyqo1X1PvAtPjw9cxBY27P7BV3b/1FV26tqrqrmZmb6XjSWJA2pb9AnCXAHsKeqbutpX93T7Srg\n5W75QWBzkjOTXAisA54ZX8mSpKUY5K6bTwKfBV5K8kLXdjNwTZINLN5yuQ/4HEBV7UqyE9jN4h07\n13vHjSRNT9+gr6ongRxj08Mn2GcbsG2EuiRJY+IjECSpccviEQjScja79aGpjLvv1iumMq7a44xe\nkhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWp\ncQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMadPu0CpEHMbn1o\n2iVIK5YzeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1Lj+gZ9krVJHk+yO8muJDd0\n7ecleSTJ97vXc3v2uSnJ3iSvJrlskgcgSTqxQWb0R4AvV9V64NeB65OsB7YCj1XVOuCxbp1u22bg\nIuBy4PYkp02ieElSf32DvqoOVdXz3fI7wB5gDbAJ2NF12wFc2S1vAu6pqveq6jVgL7Bx3IVLkgaz\npHP0SWaBi4GngVVVdajb9AawqlteA+zv2e1A1/bR99qSZD7J/MLCwhLLliQNauCgT3I2cC9wY1W9\n3butqgqopQxcVduraq6q5mZmZpayqyRpCQYK+iRnsBjyd1XVfV3zm0lWd9tXA4e79oPA2p7dL+ja\nJElTMMhdNwHuAPZU1W09mx4Eru2WrwUe6GnfnOTMJBcC64BnxleyJGkpBnke/SeBzwIvJXmha7sZ\nuBXYmeQ64HXgaoCq2pVkJ7CbxTt2rq+qo2OvXJI0kL5BX1VPAjnO5kuPs882YNsIdUmSxsRPxkpS\n4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMGeQSCpCmY3frQ1Mbed+sVUxtb\n4+eMXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mN\nM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TG9Q36JHcm\nOZzk5Z62ryY5mOSF7uczPdtuSrI3yatJLptU4ZKkwQwyo/82cPkx2r9RVRu6n4cBkqwHNgMXdfvc\nnuS0cRUrSVq6vkFfVU8Abw34fpuAe6rqvap6DdgLbByhPknSiEY5R//FJC92p3bO7drWAPt7+hzo\n2iRJUzJs0H8T+ASwATgEfH2pb5BkS5L5JPMLCwtDliFJ6meooK+qN6vqaFW9D3yLD0/PHATW9nS9\noGs71ntsr6q5qpqbmZkZpgxJ0gCGCvokq3tWrwI+uCPnQWBzkjOTXAisA54ZrURJ0ihO79chyd3A\nJcD5SQ4AtwCXJNkAFLAP+BxAVe1KshPYDRwBrq+qo5MpXZI0iL5BX1XXHKP5jhP03wZsG6UoSdL4\n+MlYSWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXO\noJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXF9vzNW6jW79aFplyBpiZzRS1LjDHpJapxB\nL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TG9Q36\nJHcmOZzk5Z6285I8kuT73eu5PdtuSrI3yatJLptU4ZKkwQwyo/82cPlH2rYCj1XVOuCxbp0k64HN\nwEXdPrcnOW1s1UqSlqxv0FfVE8BbH2neBOzolncAV/a031NV71XVa8BeYOOYapUkDWHYc/SrqupQ\nt/wGsKpbXgPs7+l3oGuTJE3JyBdjq6qAWup+SbYkmU8yv7CwMGoZkqTjGDbo30yyGqB7Pdy1HwTW\n9vS7oGv7f6pqe1XNVdXczMzMkGVIkvoZNugfBK7tlq8FHuhp35zkzCQXAuuAZ0YrUZI0itP7dUhy\nN3AJcH6SA8AtwK3AziTXAa8DVwNU1a4kO4HdwBHg+qo6OqHaJUkD6Bv0VXXNcTZdepz+24BtoxQl\nSRofPxkrSY0z6CWpcX1P3Ug69cxufWgq4+679YqpjNs6Z/SS1DiDXpIaZ9BLUuMMeklqnEEvSY0z\n6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMb5xSMr0LS+\nFELSyuSMXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxB\nL0mNM+glqXEGvSQ1bqTHFCfZB7wDHAWOVNVckvOAfwZmgX3A1VX1X6OVKUka1jhm9L9ZVRuqaq5b\n3wo8VlXrgMe6dUnSlEzi1M0mYEe3vAO4cgJjSJIGNGrQF/BokueSbOnaVlXVoW75DWDVsXZMsiXJ\nfJL5hYWFEcuQJB3PqF8l+KmqOpjk54FHkrzSu7GqKkkda8eq2g5sB5ibmztmH0nS6Eaa0VfVwe71\nMHA/sBF4M8lqgO718KhFSpKGN3TQJzkryTkfLAOfBl4GHgSu7bpdCzwwapGSpOGNcupmFXB/kg/e\n55+q6l+TPAvsTHId8Dpw9ehlSpKGNXTQV9UPgF87RvuPgEtHKUqSND5+MlaSGmfQS1LjDHpJapxB\nL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS40Z9TLEkjc3s1oemMu6+W6+YyrgnizN6SWqc\nQS9JjTPoJalxBr0kNc6LsSOY1oUjSVoKZ/SS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXO\noJekxhn0ktQ4g16SGmfQS1LjfNaNpFPeNJ9bdTK+9MQZvSQ1zqCXpMYZ9JLUOINekhrXxMVYvwBE\nko5vYjP6JJcneTXJ3iRbJzWOJOnEJhL0SU4D/gH4HWA9cE2S9ZMYS5J0YpOa0W8E9lbVD6rqf4B7\ngE0TGkuSdAKTCvo1wP6e9QNdmyTpJJvaxdgkW4At3eq7SV6dwDDnAz+cwPuebB7H8uJxLC8r+jjy\ntZ8sDnMcvzBIp0kF/UFgbc/6BV3bT1TVdmD7hMYHIMl8Vc1NcoyTweNYXjyO5cXj6G9Sp26eBdYl\nuTDJTwGbgQcnNJYk6QQmMqOvqiNJvgB8FzgNuLOqdk1iLEnSiU3sHH1VPQw8PKn3H9BETw2dRB7H\n8uJxLC8eRx+pqkm9tyRpGfBZN5LUuOaDPslfJXkxyQtJvpfk49OuaRhJ/jrJK92x3J/k56Zd0zCS\n/H6SXUneT7Ki7pRo5bEeSe5McjjJy9OuZVhJ1iZ5PMnu7u/TDdOuaRhJfjrJM0n+ozuOv5jIOK2f\nuknys1X1drf8JWB9VX1+ymUtWZJPA//WXej+GkBV/dmUy1qyJL8MvA/8I/AnVTU/5ZIG0j3W4z+B\n32bxA4DPAtdU1e6pFjaEJL8BvAt8p6p+Zdr1DCPJamB1VT2f5BzgOeDKlfbnkSTAWVX1bpIzgCeB\nG6rqqXGO0/yM/oOQ75wFrMjfbFX1vao60q0+xeJnE1acqtpTVZP4cNykNfNYj6p6Anhr2nWMoqoO\nVdXz3fI7wB5W4Kfva9G73eoZ3c/YM6r5oAdIsi3JfuAPgD+fdj1j8EfAv0y7iFOMj/VYppLMAhcD\nT0+3kuEkOS3JC8Bh4JGqGvtxNBH0SR5N8vIxfjYBVNVXqmotcBfwhelWe3z9jqPr8xXgCIvHsiwN\nchzSOCQ5G7gXuPEj/3tfMarqaFVtYPF/6RuTjP10WhNfPFJVvzVg17tYvLf/lgmWM7R+x5HkD4Hf\nBS6tZXxxZQl/HitJ38d66OTqzmnfC9xVVfdNu55RVdWPkzwOXA6M9UJ5EzP6E0myrmd1E/DKtGoZ\nRZLLgT8Ffq+q/nva9ZyCfKzHMtJdxLwD2FNVt027nmElmfngDrokP8Pixf6xZ9SpcNfNvcAvsXin\nx+vA56tqxc3EkuwFzgR+1DU9tULvHroK+HtgBvgx8EJVXTbdqgaT5DPA3/LhYz22TbmkoSS5G7iE\nxaclvgncUlV3TLWoJUryKeDfgZdY/LcNcHP3ifwVI8mvAjtY/Dv1MWBnVf3l2MdpPegl6VTX/Kkb\nSTrVGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXufwGbo6TpZ5CZeAAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10492c898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(norm_data)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:\n",
      "[[-0.89578605  1.02302504]]\n",
      "W:\n",
      "[[-0.84239441 -0.42819193]\n",
      " [ 1.61024034  0.26591325]\n",
      " [ 1.62706041 -2.04730439]]\n",
      "X:\n",
      "[[ 0.40000001  0.2         0.40000001]\n",
      " [ 0.30000001  0.40000001  0.5       ]\n",
      " [ 0.30000001 -0.40000001  0.5       ]]\n",
      "y:\n",
      "[[ 0.4353953   0.52148902]\n",
      " [ 0.57667089  0.49432039]\n",
      " [ 0.2730763   0.44140792]]\n"
     ]
    }
   ],
   "source": [
    "# X維度是3x3\n",
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([1, 2]))\n",
    "X = tf.placeholder(\"float\", [None,3])\n",
    "y=tf.nn.sigmoid(tf.matmul(X,W)+b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    X_array = np.array([[0.4,0.2 ,0.4],\n",
    "                        [0.3,0.4 ,0.5],\n",
    "                        [0.3,-0.4,0.5]])    \n",
    "    (_b,_W,_X,_y)=sess.run((b,W,X,y),feed_dict={X:X_array})\n",
    "    \n",
    "    print('b:')\n",
    "    print(_b)    \n",
    "    print('W:')\n",
    "    print(_W)\n",
    "    print('X:')\n",
    "    print(_X)\n",
    "    print('y:')\n",
    "    print(_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正式定義神經層！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer(output_dim,input_dim,inputs, activation=None):\n",
    "    W = tf.Variable(tf.random_normal([input_dim, output_dim])) #rand: in x out \n",
    "    b = tf.Variable(tf.random_normal([1, output_dim])) #rand: 1 x out\n",
    "    XWb = tf.matmul(inputs, W) + b\n",
    "    if activation is None:\n",
    "        outputs = XWb\n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[ 0.40000001  0.2         0.40000001  0.1       ]\n",
      " [ 0.30000001  0.40000001  0.5         0.30000001]\n",
      " [ 0.30000001 -0.40000001  0.5         0.2       ]]\n",
      "y:\n",
      "[[ 0.44149762  0.          0.        ]\n",
      " [ 0.50783324  0.          0.03453216]\n",
      " [ 0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(\"float\", [None,4])\n",
    "\n",
    "y = layer(output_dim=3,input_dim=4,inputs=X,  # 3x4\n",
    "          activation=tf.nn.relu)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    #X一定是是 nx4維度才能符合上面運作\n",
    "    X_array = np.array([[0.4,0.2 ,0.4,0.1],\n",
    "                        [0.3,0.4 ,0.5,0.3],\n",
    "                        [0.3,-0.4,0.5,0.2]])    \n",
    "    (_X,_y)= sess.run((X,y), feed_dict={X:X_array})\n",
    "    \n",
    "    print('X:')\n",
    "    print(_X) #X的樣子\n",
    "    print('y:')\n",
    "    print(_y) #y的output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input Layer X:\n",
      "[[ 0.40000001  0.2         0.40000001  0.5       ]]\n",
      "hidden Layer h:\n",
      "[[ 0.          1.28631115  1.15463614]]\n",
      "output Layer y:\n",
      "[[-0.77611375  5.66346598]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(\"float\", [None,4])\n",
    "h = layer(output_dim=3,input_dim=4,inputs=X, activation=tf.nn.relu)\n",
    "y = layer(output_dim=2,input_dim=3,inputs=h)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    X_array = np.array([[0.4,0.2 ,0.4,0.5]])    \n",
    "    (layer_X,layer_h,layer_y) = sess.run((X,h,y),feed_dict={X:X_array})\n",
    "    \n",
    "    print('input Layer X:')\n",
    "    print(layer_X) #layer所獲得的output\n",
    "    print('hidden Layer h:')\n",
    "    print(layer_h) #layer所獲得的output\n",
    "    print('output Layer y:')\n",
    "    print(layer_y) #layer所獲得的output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug，回溯神經元層的Output和參數們（W, b）！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#原本的神經層只會回傳Output\n",
    "#這個dubug用的會回傳Output, W 和 b\n",
    "\n",
    "def layer_debug(output_dim,input_dim,inputs, activation=None):\n",
    "    W = tf.Variable(tf.random_normal([input_dim, output_dim]))\n",
    "    b = tf.Variable(tf.random_normal([1, output_dim]))\n",
    "    XWb = tf.matmul(inputs, W) + b\n",
    "    if activation is None:\n",
    "        outputs = XWb\n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    return outputs,W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input Layer X:\n",
      "[[ 0.40000001  0.2         0.40000001  0.5       ]]\n",
      "W1:\n",
      "[[ -9.88278687e-01   1.51206136e+00   5.92093050e-01]\n",
      " [  2.17260391e-01  -6.09053493e-01   3.10589933e+00]\n",
      " [ -7.28750527e-01   4.96300571e-02  -5.63648880e-01]\n",
      " [ -1.79390645e+00  -2.24799104e-03  -4.52206910e-01]]\n",
      "b1:\n",
      "[[-0.93255407  0.97652829 -2.02141666]]\n",
      "hidden Layer h:\n",
      "[[ 0.          1.47827005  0.        ]]\n",
      "W2:\n",
      "[[ 0.97075099  0.64354968]\n",
      " [-0.669052    0.68345618]\n",
      " [ 0.02815941 -0.38623917]]\n",
      "b2:\n",
      "[[ 1.53139627 -0.1617934 ]]\n",
      "output Layer y:\n",
      "[[ 0.54235673  0.84853941]]\n"
     ]
    }
   ],
   "source": [
    "#這個dubug用的會回傳Output, W 和 b\n",
    "X = tf.placeholder(\"float\", [None,4])\n",
    "h, W1, b1 = layer_debug(output_dim=3,input_dim=4,inputs=X, activation=tf.nn.relu)\n",
    "y, W2, b2 = layer_debug(output_dim=2,input_dim=3,inputs=h)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    X_array = np.array([[0.4, 0.2, 0.4, 0.5]])    \n",
    "    (layer_X,layer_h,layer_y,W1,b1,W2,b2) = sess.run((X,h,y,W1,b1,W2,b2),feed_dict={X:X_array})\n",
    "    \n",
    "    print('input Layer X:')\n",
    "    print(layer_X) \n",
    "    print('W1:')\n",
    "    print(  W1)    \n",
    "    print('b1:')\n",
    "    print(  b1)    \n",
    "    print('hidden Layer h:')\n",
    "    print(layer_h)    \n",
    "    print('W2:')\n",
    "    print(  W2)    \n",
    "    print('b2:')\n",
    "    print(  b2)    \n",
    "    print('output Layer y:')\n",
    "    print(layer_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
